{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 🤖 AgentPro Quick Start Guide\n",
        "\n",
        "This notebook will walk you through how to set up and use [AgentPro](https://github.com/traversaal-ai/AgentPro) — a production-ready open-source agent framework built by [Traversaal.ai](https://traversaal.ai) for building powerful, modular, and multi-functional AI agents.\n",
        "\n",
        "### What is AgentPro?\n",
        "AgentPro lets you build intelligent agents that can:\n",
        "- Use language models (like OpenAI’s GPT) as reasoning engines\n",
        "- Solve real-world tasks such as research, automation, and knowledge retrieval\n",
        "- Scale up with custom tools, memory, and orchestration features\n",
        "\n",
        "Whether you're a developer, researcher, or AI enthusiast — this guide will help you:\n",
        "- Build and integrate your own tools with AgentPro\n"
      ],
      "metadata": {
        "id": "CyxnkWVzhqOi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Clone AgentPro and Install Dependencies\n",
        "\n",
        "To get started with **AgentPro**, begin by cloning the official GitHub repository and installing its dependencies."
      ],
      "metadata": {
        "id": "Fi5Eth4ge70O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCGHQVf-Q2Zj",
        "outputId": "0d96e6ba-716a-4f08-a6f5-99f969a99a39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.0/647.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for agentpro (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/traversaal-ai/AgentPro.git -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Set Your API Key"
      ],
      "metadata": {
        "id": "SLfWC5m9fUpT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use OpenAI models with AgentPro, you’ll need an API key from OpenAI. Follow these steps:\n",
        "\n",
        "1. Go to the [OpenAI API platform](https://platform.openai.com/)\n",
        "2. Log in or create an account\n",
        "3. Click \"Create new secret key\"\n",
        "4. Copy the generated key and paste it into the notebook like this:"
      ],
      "metadata": {
        "id": "2vlEmkaNgjwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"<openai_api_key>\""
      ],
      "metadata": {
        "id": "4tV4Qe1RUGcI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Create a Custom Tool\n",
        "AgentPro is designed to be extensible — you can easily define your own tools for domain-specific tasks.\n",
        "\n",
        "Below is an example of a **custom tool** that queries the Hugging Face Hub and returns the **most downloaded model** for a given task:"
      ],
      "metadata": {
        "id": "LMFP4v5zZmlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import list_models\n",
        "\n",
        "# Define the task you're interested in\n",
        "task_name = \"text-classification\"\n",
        "\n",
        "# Get the most downloaded model for the specified task\n",
        "models = list_models(filter=task_name, sort=\"downloads\", direction=-1)\n",
        "top_model = next(iter(models))\n",
        "\n",
        "# Print the model ID\n",
        "print(top_model.id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_wgIOdcWEYP",
        "outputId": "a22d66dc-f55b-4c0c-8b9f-94877a33aa82"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "distilbert/distilbert-base-uncased-finetuned-sst-2-english\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Define your tool using AgentPro Tool class"
      ],
      "metadata": {
        "id": "Zbn0sZDqZwyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os\n",
        "from agentpro import ReactAgent\n",
        "from agentpro.tools import Tool\n",
        "from huggingface_hub import list_models\n",
        "from typing import Any\n",
        "from agentpro import create_model\n",
        "\n",
        "class MostModelTool(Tool):\n",
        "    name: str = \"Most Downloaded Model Finder\" # Human-readable tool name\n",
        "    description: str = \"Finds the most downloaded model for a given task on Hugging Face.\" # Brief explanation of tool for agent\n",
        "    action_type: str = \"find_top_model\" # Use lowercase letters with underscores for agent; avoid spaces, digits and special characters\n",
        "    input_format: str = \"Task name as a string. Example: 'text-classification'\" # Expected input dtype with example\n",
        "\n",
        "    def run(self, input_text: Any) -> str:\n",
        "        task_name = input_text.strip()\n",
        "        models = list_models(filter=task_name, sort=\"downloads\", direction=-1)\n",
        "        top_model = next(models)\n",
        "        return top_model.id"
      ],
      "metadata": {
        "id": "zFrDw_enVAcq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Pass tool to AgentPro"
      ],
      "metadata": {
        "id": "3YHUz6e8ZzPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate your tools and ReactAgent\n",
        "tools = [MostModelTool()]\n",
        "\n",
        "# Create a model with OpenAI\n",
        "model = create_model(provider=\"openai\", model_name=\"gpt-4o\", api_key=os.getenv(\"OPENAI_API_KEY\", None))\n",
        "\n",
        "myagent = ReactAgent(model=model, tools=tools)\n",
        "\n",
        "# Run\n",
        "query = \"Can you give me the name of the model that has the most downloads in the 'text-classification' task on the Hugging Face Hub?\"\n",
        "response = myagent.run(query)\n",
        "# Can you give me the name of the model that has the most downloads in the 'text-classification' task on the Hugging Face Hub?\n",
        "# Find the most popular model used for 'object-detection' on Hugging Face.\n",
        "\n",
        "print(f\"\\nFinal Answer: {response.final_answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47wUizrrVPTr",
        "outputId": "02806366-6c79-4de7-cff2-71b7314ac7ad"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================== Iteration 1 \n",
            "✅  [Debug] Sending System Prompt (with history) to LLM:\n",
            "You are an AI assistant that follows the ReAct (Reasoning + Acting) pattern.\n",
            "        \n",
            "Your goal is to help users by breaking down complex tasks into a series of thought-out steps and actions.\n",
            "\n",
            "You have access to these tools: find_top_model\n",
            "\n",
            "Tool: Most Downloaded Model Finder\n",
            "Description: Finds the most downloaded model for a given task on Hugging Face.\n",
            "Action Type: find_top_model\n",
            "Input Format: Task name as a string. Example: 'text-classification'\n",
            "\n",
            "\n",
            "Your task is to:\n",
            "1. Think about what action is required — Thought.\n",
            "2. Take an appropriate action — Action.\n",
            "3. Repeat Thought/Action as needed until you find the final answer.\n",
            "\n",
            "### Format (Choose only one per response)\n",
            "\n",
            "Option 1 — When action is needed:\n",
            "Thought: Your reasoning about action and observation.\n",
            "Action: {\"action_type\": \"<action_type>\", \"input\": <input_data>}\n",
            "\n",
            "Option 2 — When you're confident in the final response:\n",
            "Thought: Now I know the answer that will be given in Final Answer.\n",
            "Final Answer: Provide a complete, well-structured response that directly addresses the original question.\n",
            "\n",
            "### Important:\n",
            "- Think step-by-step.\n",
            "- Never provide both Action and Final Answer or multiple Action in the same response.\n",
            "- Use available tools wisely.\n",
            "- If stuck, reflect and retry but never hallucinate.\n",
            "- If observation is empty or not related, reflect and retry but never hallucinate.\n",
            "- The current date is May 14, 2025.\n",
            "- If you follow the format strictly, you will be recognized as an excellent and trustworthy AI assistant.\n",
            "\n",
            "\n",
            "Question: Can you give me the name of the model that has the most downloads in the 'text-classification' task on the Hugging Face Hub?\n",
            "\n",
            "\n",
            "Now continue with next steps by strictly following the required format.\n",
            "\n",
            "==================================================\n",
            "🤖 [Debug] Step LLM Response:\n",
            "Thought: To find the model with the most downloads for the 'text-classification' task on the Hugging Face Hub, I need to use the Most Downloaded Model Finder tool with the specified task name.\n",
            "Action: {\"action_type\": \"find_top_model\", \"input\": \"text-classification\"}\n",
            "✅ Parsed Thought: To find the model with the most downloads for the 'text-classification' task on the Hugging Face Hub, I need to use the Most Downloaded Model Finder tool with the specified task name.\n",
            "✅ Parsed Action JSON: {\"action_type\": \"find_top_model\", \"input\": \"text-classification\"}\n",
            "✅ Parsed Action Results: distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
            "================================================== Iteration 2 \n",
            "🤖 [Debug] Step LLM Response:\n",
            "Thought: Now I know the answer that will be given in Final Answer.\n",
            "Final Answer: The model with the most downloads for the 'text-classification' task on the Hugging Face Hub is \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\".\n",
            "✅ Parsed Thought: Now I know the answer that will be given in Final Answer.\n",
            "✅ Parsed Final Answer: The model with the most downloads for the 'text-classification' task on the Hugging Face Hub is \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\".\n",
            "\n",
            "Final Answer: The model with the most downloads for the 'text-classification' task on the Hugging Face Hub is \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pf8Y3xCcWhyl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}